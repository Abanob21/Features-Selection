{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from math import sqrt\n",
    "import itertools\n",
    "\n",
    "\n",
    "def extract_features(index, dataset): # function that takes list of feature names and returns those features only from dataset\n",
    "    return dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = input(\"Type in the name of the file to test: \")\n",
    "print(\"1) Forward Selection \\n2) Backward Elimination\") # User input for the algorithm\n",
    "algo = int(input(\"Type the number of the algorithm you want to run:\"))\n",
    "data = open(filename).read() # reading dataset\n",
    "data = data.split(\"\\n\") # spliting whole data with new lines\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in data:\n",
    "    if len(i) > 1: \n",
    "        i = i.strip() # removing extra spaces\n",
    "        line = i.split(\"  \") # spliting each feature within single data point\n",
    "        y.append(float(line[0])) # storing the target column\n",
    "        single_instance = [] \n",
    "        for j in line[1:]:\n",
    "            single_instance.append(float(j)) # stroing all features of single instance (data point)\n",
    "        X.append(single_instance) \n",
    "        \n",
    "df = pd.DataFrame(X) # converting the list into a pandas dataframe\n",
    "arr = df.to_numpy()\n",
    "df.columns = range(1, len(X[0]) + 1) # naming the column with feature names\n",
    "# CS170_Small_Data__96.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data, y, k = 5):\n",
    "    neighbours = []\n",
    "    predictions = []\n",
    "    \n",
    "    for index in range(len(data)): # iterating over all the datapoints\n",
    "        neighbours = []\n",
    "        datapoint = data.iloc[index]  # taking single datapoint\n",
    "        edf = pow((datapoint - data), 2) # taking difference of the datapoint with rest of the datapoints in the dataset\n",
    "        sumdf = edf.sum(axis = 1) # taking sum of the rows we got \n",
    "        sumdf = sumdf **(1/2) # euclidean # taking square root of the sum of the rows\n",
    "        # so far we have calculated the scores \n",
    "        sortedseries = sumdf.sort_values(ascending=True)  # sorted scores\n",
    "        n = list(sortedseries.index)[1: k + 1] # taking k nearest neighbours\n",
    "        for i in n: \n",
    "            neighbours.append(y[i])  \n",
    "        res = max(set(neighbours), key = neighbours.count) # taking majority of the classes\n",
    "        predictions.append(res) # appending the prediction (majority) to the list\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "final_features = []\n",
    "best = 0.0\n",
    "\n",
    "visited = []\n",
    "\n",
    "\n",
    "graph_x = []\n",
    "graph_y = []\n",
    "\n",
    "best_feature = None\n",
    "alltimebest = []\n",
    "if algo == 1: # forward selection\n",
    "    for i in range(1, len(X[0]) + 2): # iterating over all the features\n",
    "        level = []\n",
    "        for subset in itertools.combinations(range(1, len(X[0]) + 1), i):\n",
    "            features = list(subset) # adding new feature\n",
    "            if best_feature:\n",
    "                if not (set(best_feature).issubset(set(features))):\n",
    "                    continue      \n",
    "            if set(features) in visited:\n",
    "                continue\n",
    "            visited.append(set(features))\n",
    "            \n",
    "            edf = extract_features(features, df) # extracting only features that are in features list\n",
    "            predictions = knn(edf, y) # initializing the KNN model\n",
    "            score = accuracy_score(y, predictions)\n",
    "            \n",
    "            print(\"Features: \", set(features), \"Accuracy: \", round(score*100,2))\n",
    "            level.append((score, features))\n",
    "            if score > best: # if the evaluated score is greater than previous best score\n",
    "                best = score # update best score \n",
    "                final_features = features\n",
    "                graph_x.append(features)\n",
    "                graph_y.append(score)\n",
    "        if len(level) != 0:\n",
    "            best_feature = max(level)\n",
    "            alltimebest.append(best_feature)\n",
    "            print(\"Best Feature is: \", best_feature[1], \"with accuracy:\", round(best_feature[0]*100,2), \"\\n\")\n",
    "            best_feature = best_feature[1]\n",
    "else:\n",
    "    visited = []\n",
    "    features = list(range(1, len(X[0]) + 1))\n",
    "    edf = extract_features(features, df) # extracting the feature\n",
    "    predictions = knn(edf, y) # initializing the KNN model\n",
    "    best = accuracy_score(y, predictions)\n",
    "    print(\"Features: \", set(features), \"Accuracy: \", round(best*100,2)) \n",
    "    for i in reversed(range(1, len(X[0]))): # iterating the loop in reverse order\n",
    "        temp = features.copy() # copying all the values\n",
    "        temp.pop((i)) # eliminating the last feature\n",
    "        if set(temp) in visited:\n",
    "            continue\n",
    "        visited.append(set(temp))\n",
    "        edf = extract_features(temp, df) # extracting the feature\n",
    "        predictions = knn(edf, y) # initializing the KNN model\n",
    "        score = accuracy_score(y, predictions)\n",
    "        print(\"Features: \", set(temp), \"Accuracy: \", round(score*100,2))\n",
    "        if score > best: # of score \n",
    "            best = score\n",
    "            features = temp\n",
    "            final_features = features\n",
    "            graph_x.append(features)\n",
    "            graph_y.append(score)\n",
    "\n",
    "# # \"CS170_Small_Data__96.txt\"\n",
    "# final_features\n",
    "end = time.time()\n",
    "graph_x = [str(x) for x in graph_x]\n",
    "timetaken = str((end - start))[0:4]\n",
    "print(\"Final Features: \", final_features)\n",
    "print(\"Algorithm took: \", timetaken, \"seconds\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(graph_x, graph_y)\n",
    "plt.xlabel('x - Features')\n",
    "plt.ylabel('y - Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "704f28f2f3075b8155ebac76dbfb6113f190a2a5ea9a1ec9ff3ea0a76650f761"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
