{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import sqrt\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_features(index, dataset): # function that takes list of feature names and returns those features only from dataset\n",
    "    index = np.array(index)\n",
    "    index = index - 1 # Subtracting 1 because in numpy number starts from 0\n",
    "    return dataset[:, index]\n",
    "\n",
    "def knn(data, y, k = 5):\n",
    "    neighbours = []\n",
    "    predictions = []\n",
    "    data = np.array(data)\n",
    "    \n",
    "    \n",
    "    for index in range(len(data)): # iterating over all the datapoints\n",
    "        neighbours = []\n",
    "        datapoint = data[index]  # taking single datapoint\n",
    "        edf = pow((datapoint - data), 2) # taking difference of the datapoint with rest of the datapoints in the dataset\n",
    "        sumdf = edf.sum(axis = 1) # taking sum of the rows we got \n",
    "        sumdf = sumdf **(1/2) # euclidean # taking square root of the sum of the rows\n",
    "        # so far we have calculated the scores \n",
    "        sortedseries = sorted(sumdf)  # sorted scores\n",
    "        sumdf = list(sumdf)\n",
    "        for i in range(1, k+1):\n",
    "            val = sortedseries[i]\n",
    "            ind = sumdf.index(val)\n",
    "            neighbours.append(y[ind]) \n",
    "        res = max(set(neighbours), key = neighbours.count) # taking majority of the classes\n",
    "        predictions.append(res) # appending the prediction (majority) to the list\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = input(\"Type in the name of the file to test: \")\n",
    "print(\"1) Forward Selection \\n2) Backward Elimination\") # User input for the algorithm\n",
    "algo = int(input(\"Type the number of the algorithm you want to run:\"))\n",
    "data = open(filename).read() # reading dataset\n",
    "data = data.split(\"\\n\") # spliting whole data with new lines\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in data:\n",
    "    if len(i) > 1: \n",
    "        i = i.strip() # removing extra spaces\n",
    "        line = i.split(\"  \") # spliting each feature within single data point\n",
    "        y.append(float(line[0])) # storing the target column\n",
    "        single_instance = [] \n",
    "        for j in line[1:]:\n",
    "            single_instance.append(float(j)) # stroing all features of single instance (data point)\n",
    "        X.append(single_instance) \n",
    "X = np.array(X)\n",
    "# CS170_Small_Data__96.txt\n",
    "# CS170_Large_Data__1.txt\n",
    "# CS170_Large_Data__21.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "final_features = []\n",
    "best = 0.0\n",
    "visited = []\n",
    "graph_x = []\n",
    "graph_y = []\n",
    "allfeatures = range(1, len(X[0]) + 1)\n",
    "best_feature = []\n",
    "alltimebest = []\n",
    "df = X #np.array(df)\n",
    "if algo == 1: # forward selection\n",
    "    for i in range(1, len(X[0]) + 2): # iterating over all the features\n",
    "#         features = [i]\n",
    "        level = []\n",
    "        level_best = 0\n",
    "        level_features = []\n",
    "        # Taking common elements from both lists\n",
    "        intersect = list(set(allfeatures) & set(best_feature))\n",
    "        for subset in allfeatures:\n",
    "            if subset in  intersect:\n",
    "                continue\n",
    "            features = [subset] + best_feature\n",
    "            edf = extract_features(features, df) # extracting only features that are in features list\n",
    "            predictions = knn(edf, y) # initializing the KNN model\n",
    "            score = accuracy_score(y, predictions)\n",
    "            print(\"Features: \", features, \"Accuracy: \", round(score*100,2))\n",
    "            if score > level_best: # if the evaluated score \n",
    "                level_best = score # update best score \n",
    "                level_features = features\n",
    "        if len(level_features) != 0:\n",
    "            best_feature = level_features\n",
    "            alltimebest.append((level_best, level_features))\n",
    "            print(\"Best Feature is: \", level_features, \"with accuracy:\", round(level_best*100,2), \"\\n\")\n",
    "            graph_x.append(level_features)\n",
    "            graph_y.append(level_best)\n",
    "else:\n",
    "    eliminated = []\n",
    "    edf = extract_features(allfeatures, df) # extracting only features that are in features list\n",
    "    predictions = knn(edf, y) # initializing the KNN model\n",
    "    best = accuracy_score(y, predictions)\n",
    "    print(\"Features: \", list(allfeatures), \"Accuracy: \",round(best*100,2))\n",
    "    Remainingfeatures = list(set(allfeatures).difference(eliminated))\n",
    "\n",
    "    for i in range(1, len(X[0]) + 2): # iterating over all the features\n",
    "\n",
    "        level_best = 0\n",
    "        level_features = []\n",
    "        \n",
    "        for subset in Remainingfeatures:\n",
    "            features = list(set(Remainingfeatures).difference([subset]))\n",
    "            if len(features) == 0:\n",
    "                break\n",
    "            edf = extract_features(features, df) # extracting only features that are in features list\n",
    "            predictions = knn(edf, y) # initializing the KNN model\n",
    "            score = accuracy_score(y, predictions)\n",
    "            print(\"Features: \", features, \"Accuracy: \", round(score*100,2))\n",
    "            if score > best: # if the evaluated score is greater than previous best score\n",
    "                best = score # update best score \n",
    "                final_features = features\n",
    "            if score > level_best:\n",
    "                level_best = score\n",
    "                level_features = features\n",
    "        if len(level_features) != 0:\n",
    "            best_feature = level_features\n",
    "            alltimebest.append((level_best, level_features))\n",
    "            print(\"Best Feature is: \", level_features, \"with accuracy:\", round(level_best*100,2), \"\\n\")\n",
    "            Remainingfeatures = level_features\n",
    "            graph_x.append(level_features)\n",
    "            graph_y.append(level_best) \n",
    "    \n",
    "\n",
    "# CS170_Small_Data__96.txt\n",
    "# CS170_Large_Data__21.txt\n",
    "# CS170_Large_Data__1.txt\n",
    "# final_features\n",
    "end = time.time()\n",
    "graph_x = [str(x) for x in graph_x]\n",
    "timetaken = str((end - start))[0:5]\n",
    "print(\"Final Features: \", max(alltimebest)[1],\"Accuracy is\" , round(max(alltimebest)[0]*100,2))\n",
    "print(\"Algorithm took: \", timetaken, \"seconds\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(graph_x, graph_y)\n",
    "plt.xlabel('x - Features')\n",
    "plt.ylabel('y - Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
